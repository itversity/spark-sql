{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting File Metadata\n",
    "\n",
    "Let us see how to get metadata for the  files stored in HDFS using `hdfs fsck` command. \n",
    "* We have files copied under HDFS location `/user/${USER}/retail_db`. We also have some sample large files copied under HDFS location `/public/randomtextwriter`. We can use `hdfs fsck` command.\n",
    "* We will first see how to get metadata of these files and then try to interpret it in subsequent topics.\n",
    "* HDFS stands for Hadoop Distributed File System. It means files are copied in distributed fashion.\n",
    "* Our cluster have master nodes and worker nodes, in this case the files will be physically copied in the worker nodes where data node process is running. We will cover this as part of the HDFS architecture.\n",
    "* Here are the details about worker nodes along with corresponding private ips.\n",
    "\n",
    "|Private ip|Full DNS|Short DNS|\n",
    "|---|---|---|\n",
    "|172.16.1.102|wn01.itversity.com|wn01|\n",
    "|172.16.1.103|wn02.itversity.com|wn02|\n",
    "|172.16.1.104|wn03.itversity.com|wn03|\n",
    "|172.16.1.107|wn04.itversity.com|wn04|\n",
    "|172.16.1.108|wn05.itversity.com|wn05|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs fsck -help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can get high level overview for a retail_db folder by using `hdfs fsck retail_db`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs fsck retail_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can get details about file names using `-files` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs fsck /user/${USER}/retail_db -files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Files in HDFS will be physically stored in worker nodes as blocks. We can get details of blocks associated with files using `-blocks` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs fsck /user/${USER}/retail_db -files -blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `-blocks` will only provide details about the names of the blocks, we need to use `-locations` as well to get the details about the worker nodes where the blocks are physically stored.\n",
    "* A block is nothing but a physical file in HDFS. We will understand more about blocks as part of the subsequent topics.\n",
    "* To understand where a block is physically stored you can get the infromation from **DatanodeInfoWithStorage** part of the output. It will contain ip address and we can get the corresponding DNS from the above table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs fsck /user/${USER}/retail_db -files -blocks -locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs fsck /public/randomtextwriter/part-m-00000 -files -blocks -locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
